{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admin API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions\n",
    "from confluent_kafka import KafkaException\n",
    "import sys\n",
    "import threading\n",
    "import logging\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "brokers = \"kafka1:9092,kafka2:9093\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': brokers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"test1p\", \"test2p\", \"test3p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = [NewTopic(topic, num_partitions=1, \n",
    "        replication_factor=1) for topic in topic_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = a.create_topics(new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create topic test1p: KafkaError{code=TOPIC_ALREADY_EXISTS,val=36,str=\"Topic 'test1p' already exists.\"}\n",
      "Topic test4p created\n",
      "Topic test3p created\n"
     ]
    }
   ],
   "source": [
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Topic {} created\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9 topics:\n",
      "  \"test2p\" with 2 partition(s)\n",
      "  \"test4p\" with 1 partition(s)\n",
      "  \"_schemas\" with 1 partition(s)\n",
      "  \"test22p\" with 2 partition(s)\n",
      "  \"test1p\" with 1 partition(s)\n",
      "  \"test3p\" with 1 partition(s)\n",
      "  \"__consumer_offsets\" with 50 partition(s)\n",
      "  \"_confluent-metrics\" with 12 partition(s)\n",
      "  \"__confluent.support.metrics\" with 1 partition(s)\n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if t.error is not None:\n",
    "        errstr = \": {}\".format(t.error)\n",
    "    else:\n",
    "        errstr = \"\"\n",
    "    print(\"  \\\"{}\\\" with {} partition(s){}\".format(t, len(t.partitions), errstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = a.delete_topics([topic_names[2]], operation_timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Topic {} deleted\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to delete topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = topic_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parts = [NewPartitions(topic, int(2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional partitions created for topic test4p\n"
     ]
    }
   ],
   "source": [
    "fs = a.create_partitions(new_parts, validate_only=False)\n",
    "# Wait for operation to finish.\n",
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Additional partitions created for topic {}\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to add partitions to topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic test4p has 2 partitions\n",
      "partition 0 leader: 1, replicas: [1], isrs: [1] errstr: \n",
      "partition 1 leader: 2, replicas: [2], isrs: [2] errstr: \n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "for t in iter(md.topics.values()):\n",
    "    if str(t)==topic:\n",
    "        l = t.partitions.values()\n",
    "        print(\"Topic {} has {} partitions\".format(t, len(l)))\n",
    "        for p in iter(l):\n",
    "            if p.error is not None:\n",
    "                errstr = \": {}\".format(p.error)\n",
    "            else:\n",
    "                errstr = \"\"\n",
    "            print(\"partition {} leader: {}, replicas: {},\" \n",
    "                  \" isrs: {} errstr: {}\".format(p.id, p.leader, p.replicas, p.isrs, errstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Topic \"test1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import sys\n",
    "conf = {'bootstrap.servers': brokers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Producer(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_callback(err, msg):\n",
    "        if err:\n",
    "            sys.stderr.write('%% Message failed delivery: %s\\n' % err)\n",
    "        else:\n",
    "            sys.stderr.write('%% Message delivered to %s [%d] @ %d\\n' %\n",
    "                             (msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,10):\n",
    "    try:\n",
    "        # Produce line (without newline)\n",
    "        print(n)\n",
    "        p.produce(topic_names[0], str(n), callback=delivery_callback)\n",
    "    except BufferError:\n",
    "        sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.poll(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from Topic test1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'bootstrap.servers': brokers, \n",
    "    'group.id': str(uuid4()), \n",
    "    'session.timeout.ms': 6000,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Consumer(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.subscribe([topic_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "             (msg.topic(), msg.partition(), msg.offset(), str(msg.key())))\n",
    "            print(msg.value())\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Topic \"test2p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': brokers}\n",
    "p = Producer(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-129-f27735018024>:5: DeprecationWarning: PY_SSIZE_T_CLEAN will be required for '#' formats\n",
      "  p.produce(topic_names[1], str(n), callback=delivery_callback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% Message delivered to test4p [1] @ 0\n",
      "% Message delivered to test4p [1] @ 1\n",
      "% Message delivered to test4p [0] @ 0\n",
      "% Message delivered to test4p [1] @ 2\n",
      "% Message delivered to test4p [1] @ 3\n",
      "% Message delivered to test4p [0] @ 1\n",
      "% Message delivered to test4p [1] @ 4\n",
      "% Message delivered to test4p [1] @ 5\n",
      "% Message delivered to test4p [0] @ 2\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,10):\n",
    "    try:\n",
    "        # Produce line (without newline)\n",
    "        print(n)\n",
    "        p.produce(topic_names[1], str(n), callback=delivery_callback)\n",
    "        p.poll(0)\n",
    "        p.flush()\n",
    "    except BufferError:\n",
    "        sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'bootstrap.servers': brokers, \n",
    "    'group.id': str(uuid4()), \n",
    "    'session.timeout.ms': 6000,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Consumer(conf)\n",
    "c.subscribe([topic_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test4p [0] at offset  0 with key  None:  b'3'\n",
      "test4p [0] at offset  1 with key  None:  b'6'\n",
      "test4p [0] at offset  2 with key  None:  b'9'\n",
      "test4p [1] at offset  0 with key  None:  b'1'\n",
      "test4p [1] at offset  1 with key  None:  b'2'\n",
      "test4p [1] at offset  2 with key  None:  b'4'\n",
      "test4p [1] at offset  3 with key  None:  b'5'\n",
      "test4p [1] at offset  4 with key  None:  b'7'\n",
      "test4p [1] at offset  5 with key  None:  b'8'\n"
     ]
    }
   ],
   "source": [
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            print(\"{} [{}] at offset  {} with key  {}:  {}\".format(msg.topic(), msg.partition(), msg.offset(), str(msg.key()), str(msg.value())))\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
